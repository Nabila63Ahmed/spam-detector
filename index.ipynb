{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filesystem access\n",
    "import os\n",
    "# for Unix filename pattern matching\n",
    "import fnmatch\n",
    "# for data analysis\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "# for natural language processing\n",
    "import nltk.tokenize as tokenizer\n",
    "from nltk import pos_tag, word_tokenize, sent_tokenize\n",
    "# for regular expression operations\n",
    "import re\n",
    "# for zipping lists\n",
    "from functools import reduce\n",
    "# for computing word syllables\n",
    "import pyphen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINGSPAM_BARE_DATASET_PATH = \"datasources/lingspam/bare\"\n",
    "SPAM_TERM_LIST_PATH = \"datasources/wcling/spam-term-list.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_spam_file_name(file_name):\n",
    "    return fnmatch.fnmatchcase(file_name, 'spmsg*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all the emails in the ten folders & save the labels (spam/not spam, or 0/1) of each email to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, file_names in os.walk(LINGSPAM_BARE_DATASET_PATH):\n",
    "    for file_name in fnmatch.filter(file_names, '*.txt'):\n",
    "        with open(os.path.join(root, file_name), 'r') as file:\n",
    "            documents.append(file.read())\n",
    "            labels.append(1 if is_spam_file_name(file_name) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Read 2893 documents\n"
     ]
    }
   ],
   "source": [
    "documents_length = len(documents)\n",
    "\n",
    "if documents_length > 0:\n",
    "    print(\"✅ Read %i documents\" % len(documents))\n",
    "else:\n",
    "    print(\"❌ Could not read any documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the emails & labels into 80% training & 20% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_documents_count = round(documents_length * 0.8)\n",
    "\n",
    "training_documents = documents[:training_documents_count]\n",
    "training_labels = labels[:training_documents_count]\n",
    "\n",
    "testing_documents = documents[training_documents_count:]\n",
    "testing_labels = labels[training_documents_count:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and transform the training emails & transform the testing emails using a CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit(training_documents)\n",
    "\n",
    "training_document_term_matrix = count_vectorizer.transform(training_documents)\n",
    "testing_document_term_matrix = count_vectorizer.transform(testing_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Naive Bayes classifier precision score: 0.975248\n",
      "🔎 Naive Bayes classifier recall score: 0.994824\n",
      "🔎 Naive Bayes classifier f-score: 0.984708\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier = MultinomialNB(alpha=1) # alpha: additive smoothing parameter\n",
    "naive_bayes_classifier.fit(training_document_term_matrix, training_labels)\n",
    "\n",
    "naive_bayes_classifier_predictions = naive_bayes_classifier.predict(testing_document_term_matrix)\n",
    "\n",
    "naive_bayes_classifier_precision_score = metrics.precision_score(testing_labels, naive_bayes_classifier_predictions, average='macro')\n",
    "naive_bayes_classifier_recall_score = metrics.recall_score(testing_labels, naive_bayes_classifier_predictions, average='macro')\n",
    "naive_bayes_classifier_f1_score = metrics.f1_score(testing_labels, naive_bayes_classifier_predictions, average='macro')\n",
    "\n",
    "print(\"🔎 Naive Bayes classifier precision score: %f\" % naive_bayes_classifier_precision_score)\n",
    "print(\"🔎 Naive Bayes classifier recall score: %f\" % naive_bayes_classifier_recall_score)\n",
    "print(\"🔎 Naive Bayes classifier f-score: %f\" % naive_bayes_classifier_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 K Neighbors classifier precision score: 0.912112\n",
      "🔎 K Neighbors classifier recall score: 0.955325\n",
      "🔎 K Neighbors classifier f-score: 0.931835\n"
     ]
    }
   ],
   "source": [
    "kneighbors_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "kneighbors_classifier.fit(training_document_term_matrix, training_labels)\n",
    "\n",
    "kneighbors_classifier_predictions = kneighbors_classifier.predict(testing_document_term_matrix)\n",
    "\n",
    "kneighbors_classifier_precision_score = metrics.precision_score(testing_labels, kneighbors_classifier_predictions, average='macro')\n",
    "kneighbors_classifier_recall_score = metrics.recall_score(testing_labels, kneighbors_classifier_predictions, average='macro')\n",
    "kneighbors_classifier_f1_score = metrics.f1_score(testing_labels, kneighbors_classifier_predictions, average='macro')\n",
    "\n",
    "print(\"🔎 K Neighbors classifier precision score: %f\" % kneighbors_classifier_precision_score)\n",
    "print(\"🔎 K Neighbors classifier recall score: %f\" % kneighbors_classifier_recall_score)\n",
    "print(\"🔎 K Neighbors classifier f-score: %f\" % kneighbors_classifier_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Random Forest classifier precision score: 0.970471\n",
      "🔎 Random Forest classifier recall score: 0.879173\n",
      "🔎 Random Forest classifier f-score: 0.917266\n"
     ]
    }
   ],
   "source": [
    "random_forest_classifier = RandomForestClassifier(random_state=0)\n",
    "random_forest_classifier.fit(training_document_term_matrix, training_labels)\n",
    "\n",
    "random_forest_classifier_predictions = random_forest_classifier.predict(testing_document_term_matrix)\n",
    "\n",
    "random_forest_classifier_precision_score = metrics.precision_score(testing_labels, random_forest_classifier_predictions, average='macro')\n",
    "random_forest_classifier_recall_score = metrics.recall_score(testing_labels, random_forest_classifier_predictions, average='macro')\n",
    "random_forest_classifier_f1_score = metrics.f1_score(testing_labels, random_forest_classifier_predictions, average='macro')\n",
    "\n",
    "print(\"🔎 Random Forest classifier precision score: %f\" % random_forest_classifier_precision_score)\n",
    "print(\"🔎 Random Forest classifier recall score: %f\" % random_forest_classifier_recall_score)\n",
    "print(\"🔎 Random Forest classifier f-score: %f\" % random_forest_classifier_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying using Readability Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_word_tokenized = [word_tokenize(document) for document in documents]\n",
    "documents_sentence_tokenized =  [sent_tokenize(document) for document in documents]\n",
    "documents_word_tagged = [pos_tag(document_word_tokenized) for document_word_tokenized in documents_word_tokenized]\n",
    "\n",
    "spam_term_list = list(filter(lambda x: x, open(SPAM_TERM_LIST_PATH, \"r\").read().split('\\n')))\n",
    "spam_term_list = [spam_sentence.lower() for spam_sentence in spam_term_list]                  \n",
    "\n",
    "dictionary = pyphen.Pyphen(lang='en_GB')\n",
    "documents_syllabafied = list(map(lambda document_word_tokenized: list(map(lambda word: len(dictionary.inserted(word).split('-')), document_word_tokenized)), documents_word_tokenized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1: The number of sentences in an email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_sentences_feature = [len(document_sentence_tokenized) for document_sentence_tokenized in documents_sentence_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Number of sentences of 1st 10 emails: [22, 35, 19, 4, 12, 58, 31, 11, 14, 18]\n"
     ]
    }
   ],
   "source": [
    "print(\"🔎 Number of sentences of 1st 10 emails: %s\" % number_of_sentences_feature[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F2: The number of verbs in an email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_verbs_feature = [len(list(filter(lambda word_tagged: word_tagged[1] == 'VB', document_word_tagged))) for document_word_tagged in documents_word_tagged]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Number of verbs in 1st 10 emails: [6, 4, 10, 3, 10, 30, 11, 8, 16, 3]\n"
     ]
    }
   ],
   "source": [
    "print(\"🔎 Number of verbs in 1st 10 emails: %s\" % number_of_verbs_feature[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F3: The number of words containing both numeric and alphabetical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabetical_regex = r\"[a-zA-Z]+\"\n",
    "numeric_regex = r\"[1-9]+\"\n",
    "\n",
    "number_of_words_containing_alphabetic_and_numeric_characters_feature = [len(list(filter(lambda word: re.search(alphabetical_regex, word) and re.search(numeric_regex, word), document_word_tokenized))) for document_word_tokenized in documents_word_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Number of words containing alphabetic & numeric characters in 1st 10 emails: [0, 0, 0, 0, 0, 1, 2, 1, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"🔎 Number of words containing alphabetic & numeric characters in 1st 10 emails: %s\" % number_of_words_containing_alphabetic_and_numeric_characters_feature[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F4: The number of words in an email that are found in the spam list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_words_that_exist_in_spam_list_feature = [reduce(lambda accumulative, document: accumulative + len(re.findall(r\"\\b\" + spam_term + r\"\\b\", document.lower())), documents, 0) for spam_term in spam_term_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Number of words in 1st 10 emails that are found in the spam list: [0, 1740, 0, 0, 0, 0, 8, 274, 303, 13]\n"
     ]
    }
   ],
   "source": [
    "print(\"🔎 Number of words in 1st 10 emails that are found in the spam list: %s\" % number_of_words_that_exist_in_spam_list_feature[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F5: The number of words in an email that have more than 3 syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_words_that_have_more_than_3_syllables_feature = list(map(lambda counts: len(counts), [list(filter(lambda count: count > 3, document_syllabafied)) for document_syllabafied in documents_syllabafied]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Number of words in 1st 10 emails that have more than 3 syllables: [30, 11, 5, 1, 4, 35, 10, 4, 4, 13]\n"
     ]
    }
   ],
   "source": [
    "print(\"🔎 Number of words in 1st 10 emails that have more than 3 syllables: %s\" % number_of_words_that_have_more_than_3_syllables_feature[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a feature matrix (list of lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-24f675646b87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeat_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-24f675646b87>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeat_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f1' is not defined"
     ]
    }
   ],
   "source": [
    "feat_matrix = [[f1[i], f2[i], f3[i], f4[i]] for i in range(len(documents))]\n",
    "print(feat_matrix[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feed the feature matrix and the labels to any of the sklearn classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## seperate feature matrix to training and test sets\n",
    "feature_train = feat_matrix[:training_documents_count]\n",
    "feature_test = feat_matrix[training_documents_count:]\n",
    "\n",
    "## Vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit(feature_train)\n",
    "\n",
    "training_feature_term_matrix = count_vectorizer.transform(feature_train)\n",
    "testing_feature_term_matrix = count_vectorizer.transform(feature_test)\n",
    "\n",
    "## feed into a classifier\n",
    "naive_bayes_classifier = MultinomialNB(alpha=1) # alpha: additive smoothing parameter\n",
    "naive_bayes_classifier.fit(training_feature_term_matrix, training_labels)\n",
    "\n",
    "naive_bayes_classifier_predictions = naive_bayes_classifier.predict(testing_feature_term_matrix)\n",
    "\n",
    "naive_bayes_classifier_precision_score = metrics.precision_score(testing_labels, naive_bayes_classifier_predictions, average='macro')\n",
    "naive_bayes_classifier_recall_score = metrics.recall_score(testing_labels, naive_bayes_classifier_predictions, average='macro')\n",
    "naive_bayes_classifier_f1_score = metrics.f1_score(testing_labels, naive_bayes_classifier_predictions, average='macro')\n",
    "\n",
    "print(\"🔎 Naive Bayes classifier precision score: %f\" % naive_bayes_classifier_precision_score)\n",
    "print(\"🔎 Naive Bayes classifier recall score: %f\" % naive_bayes_classifier_recall_score)\n",
    "print(\"🔎 Naive Bayes classifier f-score: %f\" % naive_bayes_classifier_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
